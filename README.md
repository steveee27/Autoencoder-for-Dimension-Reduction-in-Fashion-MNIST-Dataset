# Autoencoder-for-Dimension-Reduction-in-Fashion-MNIST-Dataset
This project uses an Autoencoder for dimension reduction on the Fashion MNIST dataset, which contains grayscale clothing images. The goal is to reduce the 784-dimensional images (28x28) to a 128-dimensional latent space while reconstructing the images. The performance is evaluated using the Structural Similarity Index (SSIM).
